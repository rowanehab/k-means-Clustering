# -*- coding: utf-8 -*-
"""DataMiningAssignment2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KkJG-kgh7RCIsxw6msyU0_YANqTvSMM_
"""

import pandas as pd
import numpy as np
from tabulate import tabulate

# Load the Excel file into a pandas dataframe
data = pd.read_excel('/content/Review_ratings.xlsx')
# Convert data values to numeric and remove any rows with missing values
data = data.apply(pd.to_numeric, errors='coerce')

def euclidean_distance(x1, x2):
    return np.sqrt(np.sum((x1 - x2) ** 2))

def initialize_centroids(data, k):
    if isinstance(data, pd.DataFrame):
        n_samples, n_features = data.shape
        centroids = np.zeros((k, n_features))
        centroid_indices = np.random.choice(range(n_samples), size=k, replace=False)
        centroids = data.values[centroid_indices]
        user_ids = data.index[centroid_indices]
    else:
        n_samples, n_features = data.shape
        centroids = np.zeros((k, n_features))
        centroid_indices = np.random.choice(range(n_samples), size=k, replace=False)
        centroids = data[centroid_indices]
        user_ids = centroid_indices
    return centroids, user_ids



# Get the number of clusters (k) from the user
k = int(input("Enter the number of clusters (k): "))

# Initialize centroids
centroids, centroid_ids = initialize_centroids(data, k)

# Print the initial centroids with their IDs
print("Initial centroids:")
print(tabulate(centroids))
print(tabulate(zip(centroid_ids, centroids), headers=["User ID", "Feature 1", "Feature 2", "Feature 3", "Feature 4"]))

def kmeans(data, k):
    # Initialize centroids
    centroids, centroid_ids = initialize_centroids(data, k)
    
    # Initialize the clusters
    clusters = [[] for _ in range(k)]
    
    # Assign each data point to the closest centroid
    while True:
        # Clear the clusters
        for cluster in clusters:
            cluster.clear()
        
        # Assign each data point to the closest centroid
        for i, sample in enumerate(data):
            distances = [euclidean_distance(sample, centroid) for centroid in centroids]
            closest_cluster = np.argmin(distances)
            clusters[closest_cluster].append(i)
        
        # Calculate new centroids from the clusters
        new_centroids = np.zeros_like(centroids)
        for i, cluster in enumerate(clusters):
            if len(cluster) != 0:
                new_centroid = np.mean(data[cluster], axis=0)
                new_centroids[i] = new_centroid
        
        # Check for convergence
        if np.allclose(new_centroids, centroids):
            break
        
        # Update centroids
        centroids = new_centroids
    
    return clusters, centroids, centroid_ids

# Read the data
data = pd.read_excel('Review_ratings.xlsx')
ratings = data.iloc[:, 1:].values
# Set the number of iterations
#print(tabulate(ratings, headers='keys', tablefmt='psql'))

# Run K-means clustering algorithm
clusters, centroids,centroid_ids = kmeans(ratings, k)

def detect_outliers(data):
    # Calculate the median and interquartile range for each feature
    medians = np.median(data, axis=0)
    iqr = np.percentile(data, 75, axis=0) - np.percentile(data, 25, axis=0)
    
    # Detect outliers based on the median and interquartile range
    lower_bounds = medians - 1.5 * iqr
    upper_bounds = medians + 1.5 * iqr
    outliers = np.logical_or(data < lower_bounds, data > upper_bounds)
    
    return outliers

# Assign each user to a cluster based on the centroids
labels = np.zeros(len(ratings))
for i, sample in enumerate(ratings):
    distances = [euclidean_distance(sample, centroid) for centroid in centroids]
    closest_cluster = np.argmin(distances)
    labels[i] = closest_cluster

# Detect outliers
outliers = detect_outliers(ratings)

# Print the clusters and their users' IDs
for i, cluster in enumerate(clusters):
    users_in_cluster = [f"User {user_index+1}" for user_index in cluster]
    print(f"Cluster {i+1} ({len(cluster)} users): {', '.join(users_in_cluster)}")
    print()

# Print a line separator
print('-' * 5000)

# Print the clusters with their outlier users
for i, cluster in enumerate(clusters):
    outlier_users = []
    for user_index in cluster:
        if np.sum(outliers[user_index]) > 0:
            outlier_users.append(f"User {user_index+1}: {df.iloc[user_index]}")
    if len(outlier_users) > 0:
        print(f"Cluster {i+1} ({len(cluster)} users):")
        print(tabulate(zip(cluster, outlier_users), headers=['User Index', 'Outlier Data']))
        if i < len(clusters) - 1:
            print('-' * 5000)  # Print a blank line between clusters